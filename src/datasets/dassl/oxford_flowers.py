import os
import random
from collections import defaultdict
from pathlib import Path

import PIL
import PIL.Image
from dassl.data.datasets import Datum
from dassl.utils import read_json
from scipy.io import loadmat
from torch.utils.data import Dataset

from .oxford_pets import OxfordPets


class OxfordFlowers(Dataset):
    dataset_dir = Path("CoOp", "oxford_flowers")

    def __init__(self, dataroot: Path, split: str, preprocess: callable):
        super().__init__()
        self.preprocess = preprocess
        self.split = split
        self.dataset_dir = dataroot / self.dataset_dir

        self.images_folder = self.dataset_dir / "jpg"
        self.label_file = self.dataset_dir / "imagelabels.mat"
        self.lab2cname_file = self.dataset_dir / "cat_to_name.json"
        self.split_path = self.dataset_dir / "split_zhou_OxfordFlowers.json"
        self.split_fewshot_dir = self.dataset_dir / "split_fewshot"

        if os.path.exists(self.split_path):
            train, val, test = OxfordPets.read_split(self.split_path, self.images_folder)
        else:
            train, val, test = self.read_data()
            OxfordPets.save_split(train, val, test, self.split_path, self.images_folder)

        subsample = "all"
        train, val, test = OxfordPets.subsample_classes(train, val, test, subsample=subsample)

        if self.split == "train":
            self.data = train
        elif self.split == "val":
            self.data = val
        elif self.split == "test":
            self.data = test
        else:
            raise ValueError(f"Invalid split: {self.split}")
        self.labels = [item.label for item in self.data]
        label2classname = {item.label: item.classname for item in self.data}
        self.classnames = [label2classname[label].replace("_", " ") for label in sorted(label2classname)]

    def __getitem__(self, index):
        image_path = str(self.data[index].impath)
        label = self.data[index].label
        image = self.preprocess(PIL.Image.open(image_path))
        image_name = f"{Path(image_path).parent.name}__{Path(image_path).name}"
        return {
            'image': image,
            'image_name': image_name,
            'label': label
        }

    def __len__(self):
        return len(self.data)

    def get_labels(self, *args, **kwargs):
        return self.labels

    def get_classnames(self, *args, **kwargs):
        return self.classnames

    def read_data(self):
        tracker = defaultdict(list)
        label_file = loadmat(str(self.label_file))["labels"][0]
        for i, label in enumerate(label_file):
            imname = f"image_{str(i + 1).zfill(5)}.jpg"
            impath = os.path.join(self.images_folder, imname)
            label = int(label)
            tracker[label].append(impath)

        print("Splitting data into 50% train, 20% val, and 30% test")

        def _collate(ims, y, c):
            items = []
            for im in ims:
                # convert to 0-based label
                item = Datum(impath=im, label=y - 1, classname=c)
                items.append(item)
            return items

        lab2cname = read_json(self.lab2cname_file)
        train, val, test = [], [], []
        for label, impaths in tracker.items():
            random.shuffle(impaths)
            n_total = len(impaths)
            n_train = round(n_total * 0.5)
            n_val = round(n_total * 0.2)
            n_test = n_total - n_train - n_val
            assert n_train > 0 and n_val > 0 and n_test > 0
            cname = lab2cname[str(label)]
            train.extend(_collate(impaths[:n_train], label, cname))
            val.extend(_collate(impaths[n_train: n_train + n_val], label, cname))
            test.extend(_collate(impaths[n_train + n_val:], label, cname))

        return train, val, test
